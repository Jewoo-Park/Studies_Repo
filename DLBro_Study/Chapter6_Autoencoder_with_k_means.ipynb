{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder의 Latent Space에 kmeans 클러스터링을 적용함"
      ],
      "metadata": {
        "id": "07R8851EENM2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtPHJWMMCNdL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment as linear_assignment #\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t31cA9gDFZqr",
        "outputId": "50069f10-4197-4a2f-afae-547583be4181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8mT7tFFdmn",
        "outputId": "fbc5cf3b-be88-4544-bea2-d9e6cda96334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 불러오기\n",
        "batch_size = 128\n",
        "num_clusters = 10\n",
        "latent_size = 10 #꼭 클러스터 개수와 같을 필요는 없음"
      ],
      "metadata": {
        "id": "M20Cm0sxFsnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETByH55FGovr",
        "outputId": "d1d1a8e7-e58f-4006-9359-6c561aca011d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.52MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.04MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    return x.view(batch_size, -1)\n",
        "\n",
        "class Deflatten(torch.nn.Module):\n",
        "  def __init__(self,k):\n",
        "    super(Deflatten, self).__init__()\n",
        "    self.k = k\n",
        "  def forward(self, x):\n",
        "    s = x.size()\n",
        "    feature_size = int((s[1]//self.k)**.5)\n",
        "    return x.view(s[0], self.k, feature_size, feature_size)\n",
        "\n",
        "class Kmeans(nn.Module):\n",
        "  def __init__(self, num_clusters, latent_size):\n",
        "    super(Kmeans, self).__init__()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    self.num_clusters = num_clusters\n",
        "    self.centroids = nn.Parameter(torch.rand((self.num_clusters, latent_size)).to(device))\n",
        "\n",
        "  def argminl2distance(self, a, b):\n",
        "    return torch.argmin(torch.sum((a - b)**2, dim=1), dim=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_assign = []\n",
        "    for m in range (x.size(0)):\n",
        "      h = x[m].expend(self.num_clusters, -1)\n",
        "      assign = self.argminl2distance(h, self.centroids)\n",
        "      y_assign.append(assign.item())\n",
        "    return y_assign, self.centroids[y_assign]"
      ],
      "metadata": {
        "id": "1TqQBwVCGuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 하이퍼파라미터 =====\n",
        "k = 16            # 베이스 채널\n",
        "latent_size = 10  # 원하는 잠재 차원 (임의로 조정 가능)\n",
        "\n",
        "# ===== Encoder / Decoder 분리 정의 =====\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size=10, k=16):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, k, 3, stride=2),      # 28 -> 13\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(k, 2*k, 3, stride=2),    # 13 -> 6\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(2*k, 4*k, 3, stride=1),  # 6 -> 4\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Flatten(),                      # 4*4*4k = 1024 (k=16이면 64*4*4)\n",
        "        )\n",
        "        self.to_latent = nn.Sequential(\n",
        "            nn.Linear(4*k*4*4, latent_size),   # 1024 -> latent_size\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.features(x)           # (N, 1024)\n",
        "        z = self.to_latent(h)          # (N, latent_size)\n",
        "        return z\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size=10, k=16):\n",
        "        super().__init__()\n",
        "        self.from_latent = nn.Sequential(\n",
        "            nn.Linear(latent_size, 4*k*4*4),  # latent_size -> 1024\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (4*k, 4, 4)),     # (N, 4k, 4, 4) = (N, 64, 4, 4)\n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(4*k, 2*k, 3, stride=1),                 # 4 -> 6\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(2*k, k, 3, stride=2),                   # 6 -> 13\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(k, 1, 3, stride=2, output_padding=1),   # 13 -> 28\n",
        "            nn.Sigmoid(),  # 입력을 [0,1]로 맞춰 학습하면 출력도 [0,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.from_latent(z)    # (N, 4k, 4, 4)\n",
        "        x_hat = self.deconv(h)     # (N, 1, 28, 28)\n",
        "        return x_hat"
      ],
      "metadata": {
        "id": "XfEac6uSJ7Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "클러스터링 정확도 함수 정의"
      ],
      "metadata": {
        "id": "Ulze8cLJKl6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_acc(y_true, y_pred):\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "\n",
        "  D=max(y_pred.max(),y_true.max())+1\n",
        "  w = np.zeros((D, D), dtype = np.int64)\n",
        "  for i in range(y_pred.size):\n",
        "    w[y_pred[i], y_true[i]] += 1\n",
        "\n",
        "  ind = linear_assignment(w.max() - w)\n",
        "  return sum([w[i, j] for i, j in zip(ind[0], ind[1])]) * 1.0 / y_pred.size\n",
        "\n",
        "def evaluation(testloader, encoder, kmeans, device):\n",
        "  predictions = []\n",
        "  actual = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "      inputs = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      latent_var = encoder(inputs)\n",
        "      y_pred, _ = kmeans(latent_var)\n",
        "      predictions += y_pred\n",
        "      actual += labels.cpu().tolist()\n",
        "\n",
        "  return cluster_acc(actual, predictions)"
      ],
      "metadata": {
        "id": "jvM5JBXFKf6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#손실함수 및 최적화 방법 정의\n",
        "encoder = Encoder(latent_size).to(device)\n",
        "decoder = Decoder(latent_size).to(device)\n",
        "kmeans = Kmeans(num_clusters, latent_size).to(device)\n",
        "\n",
        "criterion1 = torch.nn.MSELoss()\n",
        "criterion2 = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(kmeans.parameters()), lr=0.001)"
      ],
      "metadata": {
        "id": "1NIuFeVRNKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하여튼 이렇게 Autoenoder의 latent space에서 Kmeans를 적용하면 더 나은 성능을 얻을 수 있다. 어쨋든 latent space가 데이터 분포의 중요한 부분을 설명하고 있기 때문\n"
      ],
      "metadata": {
        "id": "X71hwetTOHtG"
      }
    }
  ]
}